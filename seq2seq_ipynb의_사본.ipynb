{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yong-again/seq2seq_lstm/blob/lyj/seq2seq_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('안녕하세요 2021년 12월 29일 입니다.')"
      ],
      "metadata": {
        "id": "FyIIsrCdVC29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nZFc8hmUZfp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "import warnings\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxvkq_wdUZfq"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('./1_구어체(1).xlsx', names=[\"SID\", \"src\", \"tar\"])\n",
        "df = df[:10000].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b7n824DUZfq"
      },
      "outputs": [],
      "source": [
        "del df['SID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxP0LNHPUZfq",
        "outputId": "de5d5736-2237-4f05-b509-acb2b672bec5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blGoyDKfUZfq",
        "outputId": "3f4140ee-addf-45bd-a8b6-b5d77ab6e6f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...</td>\n",
              "      <td>Bible Coloring' is a coloring application that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>씨티은행에서 일하세요?</td>\n",
              "      <td>Do you work at a City bank?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n",
              "      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n",
              "      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n",
              "      <td>I would feel grateful to know how many stocks ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>F/W 겐조타이거 키즈와 그리고 이번에 주문한 키즈 중 부족한 수량에 대한 환불입니다.</td>\n",
              "      <td>18fw Kenzo Tiger Kids, and refund for lacking ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>강아지들과 내 사진을 보낼게.</td>\n",
              "      <td>And I'll send you a picture of me and my dogs.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>그 수익금 중 일부를 위안부 할머니들을 위해 쓰고 그들을 위해 여러 가지 캠페인을 ...</td>\n",
              "      <td>Part of profits are used for the comfort women...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>그들은 내가 잘하는 것을 바탕으로 별명을 사용하고 있기 때문에 나는 사람들이 치타라...</td>\n",
              "      <td>I feel happy when people call me cheetah becau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>그러므로 실제로 컴퓨터 프로그램을 만든 사람이 프로그램에 대한 저작자가 돼요.</td>\n",
              "      <td>So, a person who made a computer program actua...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 src  \\\n",
              "0  'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...   \n",
              "1                                       씨티은행에서 일하세요?   \n",
              "2              푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.   \n",
              "3   11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.   \n",
              "4     6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.   \n",
              "5   F/W 겐조타이거 키즈와 그리고 이번에 주문한 키즈 중 부족한 수량에 대한 환불입니다.   \n",
              "6                                   강아지들과 내 사진을 보낼게.   \n",
              "7  그 수익금 중 일부를 위안부 할머니들을 위해 쓰고 그들을 위해 여러 가지 캠페인을 ...   \n",
              "8  그들은 내가 잘하는 것을 바탕으로 별명을 사용하고 있기 때문에 나는 사람들이 치타라...   \n",
              "9        그러므로 실제로 컴퓨터 프로그램을 만든 사람이 프로그램에 대한 저작자가 돼요.   \n",
              "\n",
              "                                                 tar  \n",
              "0  Bible Coloring' is a coloring application that...  \n",
              "1                        Do you work at a City bank?  \n",
              "2  PURITO's bestseller, which recorded 4th rough ...  \n",
              "3  In Chapter 11 Jesus called Lazarus from the to...  \n",
              "4  I would feel grateful to know how many stocks ...  \n",
              "5  18fw Kenzo Tiger Kids, and refund for lacking ...  \n",
              "6     And I'll send you a picture of me and my dogs.  \n",
              "7  Part of profits are used for the comfort women...  \n",
              "8  I feel happy when people call me cheetah becau...  \n",
              "9  So, a person who made a computer program actua...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQVnao_nUZfq",
        "outputId": "78df3fa2-430c-4702-ff80-d4cde5794888"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>얼마 전 가진 A사와의 회의 결과, 본계약의 계약 시점은 약간 지연된다고 합니다.</td>\n",
              "      <td>\\t As a result of the meeting with A company t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4657</th>\n",
              "      <td>A 대학교는 항공과 해양스포츠 분야의 수준 높은 시설과 교육을 겸비한 학교입니다.</td>\n",
              "      <td>\\t A university is combined with high-class fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8393</th>\n",
              "      <td>가장 인기 있는 호텔은 시내 접근성이 좋고 저렴한 호텔입니다.</td>\n",
              "      <td>\\t The most popular hotel has good accessibili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>2번 사진은 내가 당신에게 준 표본입니다.</td>\n",
              "      <td>\\t Picture 2 is the sample that I gave to you. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1278</th>\n",
              "      <td>캐시는 이미 결혼한 사람이에요.</td>\n",
              "      <td>\\t Kathy is already married. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6878</th>\n",
              "      <td>Smith씨 댁으로 가게 된 교환학생 Ann입니다.</td>\n",
              "      <td>\\t My name is Ann who is an exchange student t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2535</th>\n",
              "      <td>1월 12-13일이라는 마감일의 기준이 어떻게 산정된 건가?</td>\n",
              "      <td>\\t How did you come up with January 12th-13th ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8891</th>\n",
              "      <td>각 이슈에 대해 네가 명확히 하고자 하는 것들은 광진을 통해 충분히 전달될 것이에요.</td>\n",
              "      <td>\\t The things you would like to clear in each ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9349</th>\n",
              "      <td>감독으로써 화려한 경력을 가진 김성근 감독의 영입이 있었으니까 이번 시즌 성적이 기...</td>\n",
              "      <td>\\t As he has such a wonderful career, the futu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3775</th>\n",
              "      <td>3일 동안 일만 하는 건 매우 힘들어요.</td>\n",
              "      <td>\\t It's really hard to work for 3 days. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    src  \\\n",
              "18        얼마 전 가진 A사와의 회의 결과, 본계약의 계약 시점은 약간 지연된다고 합니다.   \n",
              "4657      A 대학교는 항공과 해양스포츠 분야의 수준 높은 시설과 교육을 겸비한 학교입니다.   \n",
              "8393                 가장 인기 있는 호텔은 시내 접근성이 좋고 저렴한 호텔입니다.   \n",
              "3256                            2번 사진은 내가 당신에게 준 표본입니다.   \n",
              "1278                                  캐시는 이미 결혼한 사람이에요.   \n",
              "6878                       Smith씨 댁으로 가게 된 교환학생 Ann입니다.   \n",
              "2535                  1월 12-13일이라는 마감일의 기준이 어떻게 산정된 건가?   \n",
              "8891    각 이슈에 대해 네가 명확히 하고자 하는 것들은 광진을 통해 충분히 전달될 것이에요.   \n",
              "9349  감독으로써 화려한 경력을 가진 김성근 감독의 영입이 있었으니까 이번 시즌 성적이 기...   \n",
              "3775                             3일 동안 일만 하는 건 매우 힘들어요.   \n",
              "\n",
              "                                                    tar  \n",
              "18    \\t As a result of the meeting with A company t...  \n",
              "4657  \\t A university is combined with high-class fa...  \n",
              "8393  \\t The most popular hotel has good accessibili...  \n",
              "3256  \\t Picture 2 is the sample that I gave to you. \\n  \n",
              "1278                    \\t Kathy is already married. \\n  \n",
              "6878  \\t My name is Ann who is an exchange student t...  \n",
              "2535  \\t How did you come up with January 12th-13th ...  \n",
              "8891  \\t The things you would like to clear in each ...  \n",
              "9349  \\t As he has such a wonderful career, the futu...  \n",
              "3775         \\t It's really hard to work for 3 days. \\n  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tar = df.tar.apply(lambda x: '\\t ' + x + ' \\n')\n",
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfNnKAH0UZfq"
      },
      "outputs": [],
      "source": [
        "# 문자 집합 구축\n",
        "src_vocab = set()\n",
        "\n",
        "for data in df.src:\n",
        "    for char in data:\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab = set()\n",
        "for data in df.tar:\n",
        "    for char in data:\n",
        "        tar_vocab.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxCpZpd2UZfr",
        "outputId": "ea6425a1-69a5-425d-d194-8451361dd230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1390 115\n"
          ]
        }
      ],
      "source": [
        "# 문자 개수\n",
        "src_vocab_size = len(src_vocab) \n",
        "tar_vocab_size = len(tar_vocab) \n",
        "\n",
        "print(src_vocab_size, tar_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIHKd9JmUZfr",
        "outputId": "8e969453-38af-4837-e3c6-f2190c8aa81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['가', '각', '간', '갇', '갈', '갉', '감', '갑', '값', '갓', '갔', '강', '갖', '같', '갚', '개', '객', '갤', '갯', '갱', '갸', '걀', '거', '걱', '건', '걷', '걸', '검', '겁', '것', '겉', '게', '겐', '겟', '겠', '겨', '격', '겪', '견', '결', '겸', '겹', '겼', '경', '곁', '계', '고', '곡', '곤', '곧']\n",
            "['M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l']\n"
          ]
        }
      ],
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[100:150])\n",
        "print(tar_vocab[45:75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "19ujkhB4UZfr",
        "outputId": "895ef9f7-9caa-4ccc-c201-034162250dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '*': 8, '+': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, '<': 25, '=': 26, '>': 27, '?': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, '_': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '~': 82, '²': 83, '·': 84, '˚': 85, 'Ω': 86, '‘': 87, '“': 88, '․': 89, '…': 90, '℃': 91, 'Ⅳ': 92, '∼': 93, '「': 94, '」': 95, '㎛': 96, '㎡': 97, '情': 98, '社': 99, '美': 100, '가': 101, '각': 102, '간': 103, '갇': 104, '갈': 105, '갉': 106, '감': 107, '갑': 108, '값': 109, '갓': 110, '갔': 111, '강': 112, '갖': 113, '같': 114, '갚': 115, '개': 116, '객': 117, '갤': 118, '갯': 119, '갱': 120, '갸': 121, '걀': 122, '거': 123, '걱': 124, '건': 125, '걷': 126, '걸': 127, '검': 128, '겁': 129, '것': 130, '겉': 131, '게': 132, '겐': 133, '겟': 134, '겠': 135, '겨': 136, '격': 137, '겪': 138, '견': 139, '결': 140, '겸': 141, '겹': 142, '겼': 143, '경': 144, '곁': 145, '계': 146, '고': 147, '곡': 148, '곤': 149, '곧': 150, '골': 151, '곰': 152, '곱': 153, '곳': 154, '공': 155, '곶': 156, '과': 157, '곽': 158, '관': 159, '괏': 160, '광': 161, '괜': 162, '괴': 163, '굉': 164, '교': 165, '구': 166, '국': 167, '군': 168, '굳': 169, '굴': 170, '굵': 171, '굶': 172, '굽': 173, '굿': 174, '궁': 175, '궂': 176, '권': 177, '궤': 178, '귀': 179, '귄': 180, '귈': 181, '귓': 182, '규': 183, '균': 184, '귤': 185, '그': 186, '극': 187, '근': 188, '글': 189, '긁': 190, '금': 191, '급': 192, '긋': 193, '긍': 194, '기': 195, '긴': 196, '길': 197, '김': 198, '깁': 199, '깃': 200, '깅': 201, '깊': 202, '까': 203, '깍': 204, '깎': 205, '깐': 206, '깔': 207, '깜': 208, '깝': 209, '깡': 210, '깨': 211, '깬': 212, '깻': 213, '꺼': 214, '꺾': 215, '껍': 216, '껏': 217, '껑': 218, '께': 219, '껴': 220, '꼈': 221, '꼭': 222, '꼴': 223, '꼼': 224, '꼽': 225, '꽂': 226, '꽃': 227, '꽉': 228, '꽤': 229, '꽹': 230, '꾀': 231, '꾸': 232, '꾹': 233, '꾼': 234, '꿀': 235, '꿈': 236, '꿉': 237, '꿔': 238, '꿨': 239, '뀌': 240, '뀐': 241, '뀔': 242, '뀝': 243, '끄': 244, '끈': 245, '끊': 246, '끌': 247, '끓': 248, '끔': 249, '끗': 250, '끝': 251, '끼': 252, '끽': 253, '낀': 254, '낄': 255, '낌': 256, '낍': 257, '나': 258, '낙': 259, '낚': 260, '난': 261, '날': 262, '낡': 263, '남': 264, '납': 265, '낫': 266, '났': 267, '낭': 268, '낮': 269, '낯': 270, '낳': 271, '내': 272, '낸': 273, '낼': 274, '냄': 275, '냅': 276, '냈': 277, '냉': 278, '냐': 279, '냑': 280, '냔': 281, '냥': 282, '너': 283, '넉': 284, '넌': 285, '널': 286, '넓': 287, '넘': 288, '넙': 289, '넛': 290, '넣': 291, '네': 292, '넥': 293, '넨': 294, '넬': 295, '넷': 296, '녀': 297, '녁': 298, '년': 299, '념': 300, '녔': 301, '녕': 302, '노': 303, '녹': 304, '논': 305, '놀': 306, '놈': 307, '농': 308, '높': 309, '놓': 310, '놔': 311, '놨': 312, '뇌': 313, '뇨': 314, '누': 315, '눈': 316, '눌': 317, '눔': 318, '눠': 319, '눴': 320, '뉘': 321, '뉜': 322, '뉠': 323, '뉴': 324, '늄': 325, '느': 326, '늑': 327, '는': 328, '늘': 329, '늙': 330, '능': 331, '늦': 332, '늬': 333, '니': 334, '닉': 335, '닌': 336, '닐': 337, '님': 338, '닙': 339, '닛': 340, '닝': 341, '다': 342, '닥': 343, '닦': 344, '단': 345, '닫': 346, '달': 347, '닭': 348, '닮': 349, '담': 350, '답': 351, '닷': 352, '당': 353, '닿': 354, '대': 355, '댁': 356, '댄': 357, '댈': 358, '댑': 359, '댓': 360, '더': 361, '덕': 362, '던': 363, '덜': 364, '덤': 365, '덥': 366, '덧': 367, '덩': 368, '덮': 369, '데': 370, '덴': 371, '델': 372, '뎁': 373, '도': 374, '독': 375, '돈': 376, '돋': 377, '돌': 378, '돔': 379, '돕': 380, '동': 381, '돛': 382, '돼': 383, '됍': 384, '됐': 385, '되': 386, '된': 387, '될': 388, '됨': 389, '됩': 390, '됬': 391, '두': 392, '둑': 393, '둔': 394, '둘': 395, '둠': 396, '둡': 397, '둥': 398, '둬': 399, '뒀': 400, '뒤': 401, '뒷': 402, '듀': 403, '듈': 404, '듐': 405, '드': 406, '득': 407, '든': 408, '듣': 409, '들': 410, '듬': 411, '듭': 412, '듯': 413, '등': 414, '디': 415, '딘': 416, '딜': 417, '딥': 418, '딨': 419, '딩': 420, '딪': 421, '따': 422, '딱': 423, '딴': 424, '딸': 425, '땀': 426, '땄': 427, '땅': 428, '때': 429, '땐': 430, '땠': 431, '땡': 432, '떠': 433, '떡': 434, '떤': 435, '떨': 436, '떴': 437, '떻': 438, '떼': 439, '뗑': 440, '또': 441, '똑': 442, '뚜': 443, '뚝': 444, '뚱': 445, '뛰': 446, '뛴': 447, '뜁': 448, '뜨': 449, '뜩': 450, '뜬': 451, '뜯': 452, '뜰': 453, '뜻': 454, '띄': 455, '띠': 456, '띤': 457, '라': 458, '락': 459, '란': 460, '랄': 461, '람': 462, '랍': 463, '랐': 464, '랑': 465, '래': 466, '랙': 467, '랜': 468, '램': 469, '랩': 470, '랫': 471, '랬': 472, '랭': 473, '략': 474, '량': 475, '러': 476, '럭': 477, '런': 478, '럴': 479, '럼': 480, '럽': 481, '럿': 482, '렀': 483, '렁': 484, '렇': 485, '레': 486, '렉': 487, '렌': 488, '렐': 489, '렘': 490, '렛': 491, '려': 492, '력': 493, '련': 494, '렬': 495, '렴': 496, '렵': 497, '렸': 498, '령': 499, '례': 500, '로': 501, '록': 502, '론': 503, '롤': 504, '롬': 505, '롭': 506, '롯': 507, '롱': 508, '뢰': 509, '료': 510, '룡': 511, '루': 512, '룩': 513, '룬': 514, '룰': 515, '룸': 516, '룹': 517, '룻': 518, '뤄': 519, '뤘': 520, '뤼': 521, '류': 522, '륙': 523, '률': 524, '륨': 525, '륭': 526, '르': 527, '른': 528, '를': 529, '름': 530, '릅': 531, '릇': 532, '릉': 533, '리': 534, '릭': 535, '린': 536, '릴': 537, '림': 538, '립': 539, '릿': 540, '링': 541, '마': 542, '막': 543, '만': 544, '많': 545, '말': 546, '맑': 547, '맘': 548, '맙': 549, '맛': 550, '망': 551, '맞': 552, '맡': 553, '매': 554, '맥': 555, '맨': 556, '맵': 557, '맷': 558, '맸': 559, '맹': 560, '맺': 561, '머': 562, '먹': 563, '먼': 564, '멀': 565, '멈': 566, '멋': 567, '멍': 568, '메': 569, '멕': 570, '멘': 571, '멜': 572, '멤': 573, '멥': 574, '멧': 575, '며': 576, '면': 577, '멸': 578, '명': 579, '몇': 580, '모': 581, '목': 582, '몬': 583, '몰': 584, '몸': 585, '몹': 586, '못': 587, '몽': 588, '묘': 589, '무': 590, '묵': 591, '묶': 592, '문': 593, '묻': 594, '물': 595, '뭄': 596, '뭇': 597, '뭉': 598, '뭐': 599, '뭔': 600, '뭘': 601, '뮌': 602, '뮤': 603, '므': 604, '미': 605, '믹': 606, '민': 607, '믿': 608, '밀': 609, '밈': 610, '밋': 611, '밌': 612, '밍': 613, '및': 614, '밑': 615, '바': 616, '박': 617, '밖': 618, '반': 619, '받': 620, '발': 621, '밝': 622, '밟': 623, '밤': 624, '밥': 625, '밧': 626, '방': 627, '밭': 628, '배': 629, '백': 630, '밴': 631, '밸': 632, '뱀': 633, '뱃': 634, '뱅': 635, '뱉': 636, '버': 637, '벅': 638, '번': 639, '벌': 640, '범': 641, '법': 642, '벗': 643, '벚': 644, '베': 645, '벤': 646, '벨': 647, '벼': 648, '벽': 649, '변': 650, '별': 651, '볍': 652, '병': 653, '보': 654, '복': 655, '볶': 656, '본': 657, '볼': 658, '봄': 659, '봅': 660, '봇': 661, '봉': 662, '봐': 663, '봤': 664, '뵈': 665, '뵐': 666, '뵙': 667, '부': 668, '북': 669, '분': 670, '불': 671, '붉': 672, '붐': 673, '붓': 674, '붕': 675, '붙': 676, '뷔': 677, '뷰': 678, '브': 679, '븐': 680, '블': 681, '비': 682, '빅': 683, '빈': 684, '빌': 685, '빔': 686, '빕': 687, '빗': 688, '빙': 689, '빚': 690, '빛': 691, '빠': 692, '빨': 693, '빵': 694, '빻': 695, '빼': 696, '뺀': 697, '뺄': 698, '뻐': 699, '뻑': 700, '뻔': 701, '뻗': 702, '뼈': 703, '뽀': 704, '뽐': 705, '뽑': 706, '뽕': 707, '뿌': 708, '뿍': 709, '뿐': 710, '뿔': 711, '쁘': 712, '쁜': 713, '쁠': 714, '쁨': 715, '쁩': 716, '사': 717, '삭': 718, '산': 719, '살': 720, '삶': 721, '삼': 722, '삽': 723, '삿': 724, '샀': 725, '상': 726, '새': 727, '색': 728, '샌': 729, '샐': 730, '샘': 731, '생': 732, '샤': 733, '샬': 734, '샴': 735, '샵': 736, '샷': 737, '샹': 738, '서': 739, '석': 740, '섞': 741, '선': 742, '설': 743, '섬': 744, '섭': 745, '섯': 746, '섰': 747, '성': 748, '세': 749, '섹': 750, '센': 751, '셀': 752, '셉': 753, '셋': 754, '셔': 755, '션': 756, '셜': 757, '셨': 758, '셰': 759, '셸': 760, '소': 761, '속': 762, '손': 763, '솔': 764, '솜': 765, '솟': 766, '송': 767, '솥': 768, '쇄': 769, '쇠': 770, '쇼': 771, '숍': 772, '숏': 773, '숑': 774, '수': 775, '숙': 776, '순': 777, '술': 778, '숨': 779, '숫': 780, '숭': 781, '숯': 782, '숲': 783, '쉐': 784, '쉬': 785, '쉴': 786, '쉼': 787, '쉽': 788, '슈': 789, '슐': 790, '슘': 791, '스': 792, '슨': 793, '슬': 794, '슴': 795, '습': 796, '슷': 797, '승': 798, '시': 799, '식': 800, '신': 801, '싣': 802, '실': 803, '싫': 804, '심': 805, '십': 806, '싱': 807, '싶': 808, '싸': 809, '싹': 810, '싼': 811, '쌀': 812, '쌈': 813, '쌉': 814, '쌍': 815, '쌓': 816, '쌩': 817, '써': 818, '썩': 819, '썬': 820, '썰': 821, '썸': 822, '썹': 823, '썼': 824, '쏘': 825, '쏜': 826, '쏟': 827, '쏠': 828, '쏩': 829, '쑥': 830, '쓰': 831, '쓴': 832, '쓸': 833, '씀': 834, '씁': 835, '씨': 836, '씩': 837, '씬': 838, '씹': 839, '씻': 840, '씽': 841, '아': 842, '악': 843, '안': 844, '앉': 845, '않': 846, '알': 847, '앓': 848, '암': 849, '압': 850, '앗': 851, '았': 852, '앙': 853, '앞': 854, '애': 855, '액': 856, '앤': 857, '앨': 858, '앰': 859, '앱': 860, '앵': 861, '야': 862, '약': 863, '얀': 864, '얇': 865, '얏': 866, '양': 867, '얗': 868, '얘': 869, '어': 870, '억': 871, '언': 872, '얹': 873, '얻': 874, '얼': 875, '얽': 876, '엄': 877, '업': 878, '없': 879, '엇': 880, '었': 881, '엉': 882, '엊': 883, '엌': 884, '엎': 885, '에': 886, '엑': 887, '엔': 888, '엘': 889, '엠': 890, '여': 891, '역': 892, '연': 893, '열': 894, '염': 895, '엽': 896, '엾': 897, '였': 898, '영': 899, '옆': 900, '예': 901, '옛': 902, '오': 903, '옥': 904, '온': 905, '올': 906, '옮': 907, '옳': 908, '옵': 909, '옷': 910, '옹': 911, '옻': 912, '와': 913, '완': 914, '왈': 915, '왔': 916, '왕': 917, '왜': 918, '왠': 919, '외': 920, '왼': 921, '요': 922, '욕': 923, '욧': 924, '용': 925, '우': 926, '욱': 927, '운': 928, '울': 929, '움': 930, '웁': 931, '웃': 932, '웅': 933, '워': 934, '원': 935, '월': 936, '웠': 937, '웨': 938, '웰': 939, '웹': 940, '위': 941, '윈': 942, '윌': 943, '윗': 944, '윙': 945, '유': 946, '육': 947, '윤': 948, '율': 949, '융': 950, '윷': 951, '으': 952, '은': 953, '을': 954, '음': 955, '읍': 956, '응': 957, '의': 958, '이': 959, '익': 960, '인': 961, '일': 962, '읽': 963, '잃': 964, '임': 965, '입': 966, '잇': 967, '있': 968, '잉': 969, '잊': 970, '잎': 971, '자': 972, '작': 973, '잔': 974, '잖': 975, '잘': 976, '잠': 977, '잡': 978, '잣': 979, '잤': 980, '장': 981, '잦': 982, '재': 983, '잭': 984, '쟁': 985, '저': 986, '적': 987, '전': 988, '절': 989, '젊': 990, '점': 991, '접': 992, '젓': 993, '정': 994, '젖': 995, '제': 996, '젝': 997, '젠': 998, '젤': 999, '젯': 1000, '져': 1001, '졌': 1002, '조': 1003, '족': 1004, '존': 1005, '졸': 1006, '좀': 1007, '좁': 1008, '종': 1009, '좋': 1010, '좌': 1011, '죄': 1012, '죠': 1013, '주': 1014, '죽': 1015, '준': 1016, '줄': 1017, '줌': 1018, '줍': 1019, '중': 1020, '줘': 1021, '줬': 1022, '쥐': 1023, '쥔': 1024, '쥘': 1025, '쥴': 1026, '즈': 1027, '즉': 1028, '즌': 1029, '즐': 1030, '즘': 1031, '즙': 1032, '증': 1033, '지': 1034, '직': 1035, '진': 1036, '질': 1037, '짐': 1038, '집': 1039, '짓': 1040, '징': 1041, '짖': 1042, '짙': 1043, '짜': 1044, '짝': 1045, '짢': 1046, '짧': 1047, '짬': 1048, '짱': 1049, '째': 1050, '짼': 1051, '쩌': 1052, '쩍': 1053, '쩔': 1054, '쩜': 1055, '쩡': 1056, '쪄': 1057, '쪽': 1058, '쫀': 1059, '쫄': 1060, '쫌': 1061, '쫓': 1062, '쭉': 1063, '쭙': 1064, '쭤': 1065, '쯔': 1066, '쯤': 1067, '찌': 1068, '찍': 1069, '찐': 1070, '찔': 1071, '찜': 1072, '찝': 1073, '차': 1074, '착': 1075, '찬': 1076, '찮': 1077, '찰': 1078, '참': 1079, '찹': 1080, '찻': 1081, '찼': 1082, '창': 1083, '찾': 1084, '채': 1085, '책': 1086, '챌': 1087, '챔': 1088, '챗': 1089, '챙': 1090, '챠': 1091, '챱': 1092, '처': 1093, '척': 1094, '천': 1095, '철': 1096, '첨': 1097, '첩': 1098, '첫': 1099, '청': 1100, '체': 1101, '첸': 1102, '첼': 1103, '쳐': 1104, '쳤': 1105, '초': 1106, '촉': 1107, '촌': 1108, '총': 1109, '촬': 1110, '최': 1111, '쵸': 1112, '추': 1113, '축': 1114, '춘': 1115, '출': 1116, '춤': 1117, '춥': 1118, '춧': 1119, '충': 1120, '춰': 1121, '췄': 1122, '취': 1123, '츄': 1124, '츠': 1125, '측': 1126, '층': 1127, '치': 1128, '칙': 1129, '친': 1130, '칠': 1131, '침': 1132, '칩': 1133, '칫': 1134, '칭': 1135, '카': 1136, '칵': 1137, '칸': 1138, '칼': 1139, '캐': 1140, '캔': 1141, '캘': 1142, '캠': 1143, '캡': 1144, '캣': 1145, '커': 1146, '컨': 1147, '컫': 1148, '컬': 1149, '컴': 1150, '컵': 1151, '컷': 1152, '컸': 1153, '케': 1154, '켄': 1155, '켈': 1156, '켐': 1157, '켓': 1158, '켜': 1159, '켰': 1160, '코': 1161, '콕': 1162, '콘': 1163, '콜': 1164, '콤': 1165, '콧': 1166, '콩': 1167, '쾌': 1168, '쿄': 1169, '쿠': 1170, '쿡': 1171, '쿤': 1172, '쿨': 1173, '쿼': 1174, '퀀': 1175, '퀄': 1176, '퀴': 1177, '퀵': 1178, '퀸': 1179, '퀼': 1180, '큐': 1181, '큘': 1182, '크': 1183, '큰': 1184, '클': 1185, '큼': 1186, '큽': 1187, '키': 1188, '킥': 1189, '킨': 1190, '킬': 1191, '킴': 1192, '킵': 1193, '킷': 1194, '킹': 1195, '타': 1196, '탁': 1197, '탄': 1198, '탈': 1199, '탐': 1200, '탑': 1201, '탓': 1202, '탔': 1203, '탕': 1204, '태': 1205, '택': 1206, '탠': 1207, '탤': 1208, '탬': 1209, '탭': 1210, '탱': 1211, '터': 1212, '턱': 1213, '턴': 1214, '털': 1215, '텀': 1216, '테': 1217, '텍': 1218, '텐': 1219, '텔': 1220, '템': 1221, '토': 1222, '톡': 1223, '톤': 1224, '톨': 1225, '톰': 1226, '톱': 1227, '통': 1228, '퇘': 1229, '퇴': 1230, '투': 1231, '툰': 1232, '툴': 1233, '툼': 1234, '퉁': 1235, '튀': 1236, '튜': 1237, '트': 1238, '특': 1239, '튼': 1240, '틀': 1241, '틈': 1242, '티': 1243, '틱': 1244, '틴': 1245, '틸': 1246, '팀': 1247, '팁': 1248, '팅': 1249, '파': 1250, '팍': 1251, '판': 1252, '팔': 1253, '팝': 1254, '팟': 1255, '팠': 1256, '팡': 1257, '팥': 1258, '패': 1259, '팩': 1260, '팬': 1261, '팸': 1262, '팹': 1263, '퍼': 1264, '펀': 1265, '펌': 1266, '펐': 1267, '페': 1268, '펙': 1269, '펜': 1270, '펠': 1271, '펩': 1272, '펫': 1273, '펴': 1274, '편': 1275, '펼': 1276, '평': 1277, '폐': 1278, '포': 1279, '폭': 1280, '폰': 1281, '폴': 1282, '폼': 1283, '퐁': 1284, '푀': 1285, '표': 1286, '푸': 1287, '푹': 1288, '푼': 1289, '풀': 1290, '품': 1291, '풋': 1292, '풍': 1293, '퓨': 1294, '프': 1295, '픈': 1296, '플': 1297, '픔': 1298, '픕': 1299, '피': 1300, '픽': 1301, '핀': 1302, '필': 1303, '핏': 1304, '핑': 1305, '하': 1306, '학': 1307, '한': 1308, '할': 1309, '함': 1310, '합': 1311, '핫': 1312, '항': 1313, '해': 1314, '핵': 1315, '핸': 1316, '햄': 1317, '햇': 1318, '했': 1319, '행': 1320, '향': 1321, '허': 1322, '헌': 1323, '헐': 1324, '험': 1325, '헝': 1326, '헤': 1327, '헥': 1328, '헨': 1329, '헬': 1330, '헷': 1331, '헹': 1332, '혀': 1333, '혁': 1334, '현': 1335, '혈': 1336, '혐': 1337, '협': 1338, '혔': 1339, '형': 1340, '혜': 1341, '호': 1342, '혹': 1343, '혼': 1344, '홀': 1345, '홈': 1346, '홉': 1347, '홋': 1348, '홍': 1349, '홑': 1350, '화': 1351, '확': 1352, '환': 1353, '활': 1354, '황': 1355, '회': 1356, '획': 1357, '횟': 1358, '횡': 1359, '효': 1360, '후': 1361, '훈': 1362, '훌': 1363, '훔': 1364, '훗': 1365, '훨': 1366, '훼': 1367, '휘': 1368, '휠': 1369, '휩': 1370, '휴': 1371, '흉': 1372, '흐': 1373, '흑': 1374, '흔': 1375, '흘': 1376, '흙': 1377, '흠': 1378, '흡': 1379, '흥': 1380, '흩': 1381, '희': 1382, '흰': 1383, '히': 1384, '힉': 1385, '힌': 1386, '힐': 1387, '힘': 1388, '힙': 1389, 'ｍ': 1390}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, '*': 12, '+': 13, ',': 14, '-': 15, '.': 16, '/': 17, '0': 18, '1': 19, '2': 20, '3': 21, '4': 22, '5': 23, '6': 24, '7': 25, '8': 26, '9': 27, ':': 28, ';': 29, '<': 30, '=': 31, '>': 32, '?': 33, 'A': 34, 'B': 35, 'C': 36, 'D': 37, 'E': 38, 'F': 39, 'G': 40, 'H': 41, 'I': 42, 'J': 43, 'K': 44, 'L': 45, 'M': 46, 'N': 47, 'O': 48, 'P': 49, 'Q': 50, 'R': 51, 'S': 52, 'T': 53, 'U': 54, 'V': 55, 'W': 56, 'X': 57, 'Y': 58, 'Z': 59, ']': 60, '^': 61, '_': 62, '`': 63, 'a': 64, 'b': 65, 'c': 66, 'd': 67, 'e': 68, 'f': 69, 'g': 70, 'h': 71, 'i': 72, 'j': 73, 'k': 74, 'l': 75, 'm': 76, 'n': 77, 'o': 78, 'p': 79, 'q': 80, 'r': 81, 's': 82, 't': 83, 'u': 84, 'v': 85, 'w': 86, 'x': 87, 'y': 88, 'z': 89, '~': 90, '£': 91, '²': 92, '·': 93, 'è': 94, 'é': 95, 'ó': 96, 'ē': 97, '˚': 98, 'Ω': 99, '\\u200b': 100, '–': 101, '—': 102, '‘': 103, '’': 104, '“': 105, '”': 106, '•': 107, '₩': 108, '℃': 109, '∼': 110, '「': 111, '」': 112, '情': 113, '社': 114, '美': 115}\n"
          ]
        }
      ],
      "source": [
        "# 문자 집합에 인덱스 부여\n",
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSTRXnEPUZfr",
        "outputId": "ae1d6e2e-8130-499c-b4d5-8a5867845f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7, 30, 64, 57, 67, 60, 1, 31, 70, 67, 70, 73, 64, 69, 62, 7, 953, 1, 748, 144, 958, 1, 842, 530, 342, 928, 1, 959, 862, 195, 529, 1, 1101, 1325, 1, 1309, 1, 775, 1, 968, 328, 1, 1149, 476, 541, 1, 860, 966, 334, 342, 12], [836, 1243, 953, 1320, 886, 739, 1, 962, 1306, 749, 922, 28], [1287, 534, 1222, 958, 1, 645, 792, 1238, 752, 476, 328, 1, 1314, 920, 886, 739, 1, 966, 761, 593, 544, 952, 501, 1, 18, 1074, 1, 914, 1252, 954, 1, 195, 502, 1306, 898, 342, 12], [15, 15, 981, 886, 739, 328, 1, 901, 775, 338, 959, 1, 959, 639, 888, 1, 258, 717, 501, 529, 1, 590, 365, 886, 739, 1, 671, 476, 272, 870, 1, 1015, 953, 1, 972, 1, 101, 928, 370, 739, 1, 720, 534, 758, 796, 334, 342, 12], [20, 12, 19, 10, 1, 21, 10, 1, 22, 1, 717, 959, 1027, 101, 1, 580, 1, 116, 258, 1, 361, 1, 983, 966, 147, 1, 388, 1034, 1, 996, 132, 1, 847, 492, 1014, 799, 577, 1, 107, 717, 1306, 135, 796, 334, 342, 12]]\n"
          ]
        }
      ],
      "source": [
        "# src 정수 인코딩\n",
        "encoder_input = []\n",
        "for data in df.src:\n",
        "    encoded_line = []\n",
        "    for char in data:\n",
        "        encoded_line.append(src_to_index[char])\n",
        "    encoder_input.append(encoded_line)\n",
        "    \n",
        "print(encoder_input[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YRZ3E_LMUZfr",
        "outputId": "9338ea95-728b-449b-c0df-a97dec7a854c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1, 3, 35, 72, 65, 75, 68, 3, 36, 78, 75, 78, 81, 72, 77, 70, 9, 3, 72, 82, 3, 64, 3, 66, 78, 75, 78, 81, 72, 77, 70, 3, 64, 79, 79, 75, 72, 66, 64, 83, 72, 78, 77, 3, 83, 71, 64, 83, 3, 64, 75, 75, 78, 86, 82, 3, 88, 78, 84, 3, 83, 78, 3, 68, 87, 79, 68, 81, 72, 68, 77, 66, 68, 3, 65, 68, 64, 84, 83, 72, 69, 84, 75, 3, 82, 83, 78, 81, 72, 68, 82, 3, 72, 77, 3, 83, 71, 68, 3, 35, 72, 65, 75, 68, 16, 3, 2], [1, 3, 37, 78, 3, 88, 78, 84, 3, 86, 78, 81, 74, 3, 64, 83, 3, 64, 3, 36, 72, 83, 88, 3, 65, 64, 77, 74, 33, 3, 2], [1, 3, 49, 54, 51, 42, 53, 48, 9, 82, 3, 65, 68, 82, 83, 82, 68, 75, 75, 68, 81, 14, 3, 86, 71, 72, 66, 71, 3, 81, 68, 66, 78, 81, 67, 68, 67, 3, 22, 83, 71, 3, 81, 78, 84, 70, 71, 3, 15, 66, 84, 83, 82, 3, 65, 88, 3, 86, 78, 81, 67, 82, 3, 78, 69, 3, 76, 78, 84, 83, 71, 3, 69, 81, 78, 76, 3, 64, 65, 81, 78, 64, 67, 16, 3, 2], [1, 3, 42, 77, 3, 36, 71, 64, 79, 83, 68, 81, 3, 19, 19, 3, 43, 68, 82, 84, 82, 3, 66, 64, 75, 75, 68, 67, 3, 45, 64, 89, 64, 81, 84, 82, 3, 69, 81, 78, 76, 3, 83, 71, 68, 3, 83, 78, 76, 65, 3, 64, 77, 67, 3, 81, 64, 72, 82, 68, 67, 3, 71, 72, 76, 3, 69, 81, 78, 76, 3, 83, 71, 68, 3, 67, 68, 64, 67, 16, 3, 2], [1, 3, 42, 3, 86, 78, 84, 75, 67, 3, 69, 68, 68, 75, 3, 70, 81, 64, 83, 68, 69, 84, 75, 3, 83, 78, 3, 74, 77, 78, 86, 3, 71, 78, 86, 3, 76, 64, 77, 88, 3, 82, 83, 78, 66, 74, 82, 3, 86, 72, 75, 75, 3, 65, 68, 3, 82, 68, 66, 84, 81, 68, 67, 3, 78, 69, 3, 82, 72, 89, 68, 3, 24, 16, 23, 14, 3, 25, 14, 3, 64, 77, 67, 3, 26, 16, 3, 2]]\n"
          ]
        }
      ],
      "source": [
        "# tar 정수 인코딩\n",
        "decoder_input = []\n",
        "for data in df.tar:\n",
        "    encoded_line = []\n",
        "    for char in data:\n",
        "        encoded_line.append(tar_to_index[char])\n",
        "    decoder_input.append(encoded_line)\n",
        "print(decoder_input[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3oTY6ZC5UZfr",
        "outputId": "12e9d370-c6ab-4879-b2cf-1bf863504794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar encoding:  [[3, 35, 72, 65, 75, 68, 3, 36, 78, 75, 78, 81, 72, 77, 70, 9, 3, 72, 82, 3, 64, 3, 66, 78, 75, 78, 81, 72, 77, 70, 3, 64, 79, 79, 75, 72, 66, 64, 83, 72, 78, 77, 3, 83, 71, 64, 83, 3, 64, 75, 75, 78, 86, 82, 3, 88, 78, 84, 3, 83, 78, 3, 68, 87, 79, 68, 81, 72, 68, 77, 66, 68, 3, 65, 68, 64, 84, 83, 72, 69, 84, 75, 3, 82, 83, 78, 81, 72, 68, 82, 3, 72, 77, 3, 83, 71, 68, 3, 35, 72, 65, 75, 68, 16, 3, 2], [3, 37, 78, 3, 88, 78, 84, 3, 86, 78, 81, 74, 3, 64, 83, 3, 64, 3, 36, 72, 83, 88, 3, 65, 64, 77, 74, 33, 3, 2], [3, 49, 54, 51, 42, 53, 48, 9, 82, 3, 65, 68, 82, 83, 82, 68, 75, 75, 68, 81, 14, 3, 86, 71, 72, 66, 71, 3, 81, 68, 66, 78, 81, 67, 68, 67, 3, 22, 83, 71, 3, 81, 78, 84, 70, 71, 3, 15, 66, 84, 83, 82, 3, 65, 88, 3, 86, 78, 81, 67, 82, 3, 78, 69, 3, 76, 78, 84, 83, 71, 3, 69, 81, 78, 76, 3, 64, 65, 81, 78, 64, 67, 16, 3, 2], [3, 42, 77, 3, 36, 71, 64, 79, 83, 68, 81, 3, 19, 19, 3, 43, 68, 82, 84, 82, 3, 66, 64, 75, 75, 68, 67, 3, 45, 64, 89, 64, 81, 84, 82, 3, 69, 81, 78, 76, 3, 83, 71, 68, 3, 83, 78, 76, 65, 3, 64, 77, 67, 3, 81, 64, 72, 82, 68, 67, 3, 71, 72, 76, 3, 69, 81, 78, 76, 3, 83, 71, 68, 3, 67, 68, 64, 67, 16, 3, 2], [3, 42, 3, 86, 78, 84, 75, 67, 3, 69, 68, 68, 75, 3, 70, 81, 64, 83, 68, 69, 84, 75, 3, 83, 78, 3, 74, 77, 78, 86, 3, 71, 78, 86, 3, 76, 64, 77, 88, 3, 82, 83, 78, 66, 74, 82, 3, 86, 72, 75, 75, 3, 65, 68, 3, 82, 68, 66, 84, 81, 68, 67, 3, 78, 69, 3, 82, 72, 89, 68, 3, 24, 16, 23, 14, 3, 25, 14, 3, 64, 77, 67, 3, 26, 16, 3, 2]]\n"
          ]
        }
      ],
      "source": [
        "# tar에 있는 '\\t' 토큰 제거 -> Dense 와 softmax 함수 위에서 단어를 출력하기 때문 SOS 토큰은 필요없음\n",
        "decoder_target = []\n",
        "for data in df.tar:\n",
        "    timestep = 0\n",
        "    encoded_line = []\n",
        "    for char in data:\n",
        "        if timestep > 0:\n",
        "            encoded_line.append(tar_to_index[char])\n",
        "        timestep += 1\n",
        "    decoder_target.append(encoded_line)\n",
        "print('tar encoding: ', decoder_target[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajaXIBsQUZfr",
        "outputId": "88a93c5a-cf80-4f25-bf55-2a6b345eeb78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86\n",
            "222\n"
          ]
        }
      ],
      "source": [
        "max_src_len = max([len(data) for data in df.src])\n",
        "max_tar_len = max([len(data) for data in df.tar])\n",
        "print(max_src_len)\n",
        "print(max_tar_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yvI50q4UZfr"
      },
      "outputs": [],
      "source": [
        "# 패딩 한국어는 최대 길이 30, 영어는 70\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=30, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=70 ,padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=70, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdHZqLSlUZfs"
      },
      "outputs": [],
      "source": [
        "# 원-핫 인코딩\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaKbxePMUZfs"
      },
      "source": [
        "# Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNI6P26-UZft"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuu_47DdUZft"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOMzqBFxUZft",
        "outputId": "78dc88c5-f36d-451c-ef43-688a0eaa113d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10000, 30, 1391), (10000, 70, 116), (10000, 70, 116))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_input.shape, decoder_input.shape, decoder_target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMDK_w9tUZft"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(None, encoder_input.shape[2]))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# 은닉셀과, 셀상태\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PP0pA2lUZft"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR3hhYTrUZfu"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(None, decoder_input.shape[2]))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "\n",
        "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_sotfmax_layer = Dense(decoder_input.shape[2], activation='softmax')\n",
        "decoder_outputs = decoder_sotfmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQRCxOyoUZfu",
        "outputId": "974f7f2b-f417-404e-dcb0-71ac065f0c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-10 00:56:59.546731: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 29s 224ms/step - loss: 2.8224 - val_loss: 2.2181\n",
            "Epoch 2/40\n",
            "125/125 [==============================] - 27s 216ms/step - loss: 1.9452 - val_loss: 1.7668\n",
            "Epoch 3/40\n",
            "125/125 [==============================] - 28s 228ms/step - loss: 1.5287 - val_loss: 1.4710\n",
            "Epoch 4/40\n",
            "125/125 [==============================] - 27s 217ms/step - loss: 1.2429 - val_loss: 1.2748\n",
            "Epoch 5/40\n",
            "125/125 [==============================] - 26s 212ms/step - loss: 1.0831 - val_loss: 2.0396\n",
            "Epoch 6/40\n",
            "125/125 [==============================] - 27s 220ms/step - loss: 1.0277 - val_loss: 1.0180\n",
            "Epoch 7/40\n",
            "125/125 [==============================] - 28s 224ms/step - loss: 0.8479 - val_loss: 0.9738\n",
            "Epoch 8/40\n",
            "125/125 [==============================] - 28s 227ms/step - loss: 0.8109 - val_loss: 0.9284\n",
            "Epoch 9/40\n",
            "125/125 [==============================] - 28s 224ms/step - loss: 0.7742 - val_loss: 0.9103\n",
            "Epoch 10/40\n",
            "125/125 [==============================] - 28s 224ms/step - loss: 0.7490 - val_loss: 0.8854\n",
            "Epoch 11/40\n",
            "125/125 [==============================] - 29s 229ms/step - loss: 0.7262 - val_loss: 0.8642\n",
            "Epoch 12/40\n",
            "125/125 [==============================] - 28s 222ms/step - loss: 0.7049 - val_loss: 0.8483\n",
            "Epoch 13/40\n",
            "125/125 [==============================] - 29s 230ms/step - loss: 0.6861 - val_loss: 0.8380\n",
            "Epoch 14/40\n",
            "125/125 [==============================] - 28s 226ms/step - loss: 0.6689 - val_loss: 0.8168\n",
            "Epoch 15/40\n",
            "125/125 [==============================] - 29s 229ms/step - loss: 0.6642 - val_loss: 0.8202\n",
            "Epoch 16/40\n",
            "125/125 [==============================] - 28s 228ms/step - loss: 0.6393 - val_loss: 0.7951\n",
            "Epoch 17/40\n",
            "125/125 [==============================] - 28s 225ms/step - loss: 0.6280 - val_loss: 0.7869\n",
            "Epoch 18/40\n",
            "125/125 [==============================] - 28s 223ms/step - loss: 0.6157 - val_loss: 0.7817\n",
            "Epoch 19/40\n",
            "125/125 [==============================] - 28s 227ms/step - loss: 0.6042 - val_loss: 0.7698\n",
            "Epoch 20/40\n",
            "125/125 [==============================] - 28s 227ms/step - loss: 0.5934 - val_loss: 0.7683\n",
            "Epoch 21/40\n",
            "125/125 [==============================] - 29s 231ms/step - loss: 0.5830 - val_loss: 0.7623\n",
            "Epoch 22/40\n",
            "125/125 [==============================] - 29s 233ms/step - loss: 0.5731 - val_loss: 0.7559\n",
            "Epoch 23/40\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 0.5637 - val_loss: 0.7512\n",
            "Epoch 24/40\n",
            "125/125 [==============================] - 29s 230ms/step - loss: 0.5544 - val_loss: 0.7470\n",
            "Epoch 25/40\n",
            "125/125 [==============================] - 29s 231ms/step - loss: 0.5449 - val_loss: 0.7485\n",
            "Epoch 26/40\n",
            "125/125 [==============================] - 28s 226ms/step - loss: 0.5366 - val_loss: 0.7451\n",
            "Epoch 27/40\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 0.5277 - val_loss: 0.7391\n",
            "Epoch 28/40\n",
            "125/125 [==============================] - 28s 227ms/step - loss: 0.5195 - val_loss: 0.7411\n",
            "Epoch 29/40\n",
            "125/125 [==============================] - 29s 235ms/step - loss: 0.5114 - val_loss: 0.7391\n",
            "Epoch 30/40\n",
            "125/125 [==============================] - 29s 233ms/step - loss: 0.5034 - val_loss: 0.7432\n",
            "Epoch 31/40\n",
            "125/125 [==============================] - 29s 230ms/step - loss: 0.4956 - val_loss: 0.7442\n",
            "Epoch 32/40\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 0.4876 - val_loss: 0.7391\n",
            "Epoch 33/40\n",
            "125/125 [==============================] - 28s 227ms/step - loss: 0.4803 - val_loss: 0.7488\n",
            "Epoch 34/40\n",
            "125/125 [==============================] - 28s 228ms/step - loss: 0.4726 - val_loss: 0.7470\n",
            "Epoch 35/40\n",
            "125/125 [==============================] - 29s 233ms/step - loss: 0.4648 - val_loss: 0.7535\n",
            "Epoch 36/40\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 0.4576 - val_loss: 0.7558\n",
            "Epoch 37/40\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 0.4500 - val_loss: 0.7555\n",
            "Epoch 38/40\n",
            "125/125 [==============================] - 29s 231ms/step - loss: 0.4547 - val_loss: 0.7578\n",
            "Epoch 39/40\n",
            "125/125 [==============================] - 29s 234ms/step - loss: 0.4380 - val_loss: 0.7616\n",
            "Epoch 40/40\n",
            "125/125 [==============================] - 29s 229ms/step - loss: 0.4303 - val_loss: 0.7718\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x287687fa0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    x=[encoder_input, decoder_input], \n",
        "    y=decoder_target, \n",
        "    batch_size=64, \n",
        "    epochs=40, \n",
        "    validation_split=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgv1V5aZUZfu",
        "outputId": "b629bdf8-8502-4a6d-db3e-5600d0846606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 1391)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 116)]  0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        1687552     ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  381952      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 116)    29812       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,099,316\n",
            "Trainable params: 2,099,316\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf1ZETwrUZfu"
      },
      "source": [
        "## 번역기 동작 시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfHJJYdNUZfu"
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGO-mcJtUZfu"
      },
      "outputs": [],
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 문장의 다음 단어 예측을 위해서 초기상태 를 이전 시점의 상태로 사용\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉상태와 셀상태를 버리지 않음\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_sotfmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_state_inputs, outputs=[decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StrpYjFVUZfu"
      },
      "outputs": [],
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsMhipYhUZfv"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict([input_seq])\n",
        "    \n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, decoder_input.shape[2]))\n",
        "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "    \n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    \n",
        "    # stop condition이 True될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이전 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        \n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "        \n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += sampled_char\n",
        "        \n",
        "        # <EOS>에 도달하거나 최대 길이를 넘으면 중단\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
        "            stop_condition = True\n",
        "        \n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1, decoder_input.shape[2]))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "        \n",
        "        #현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value= [h, c]\n",
        "        \n",
        "    return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiRxcfbrUZfv"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from statistics import median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMC2abRiUZfv",
        "outputId": "0e544aa6-ec02-4f2a-f532-14b80ae7056b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력문장:  씨티은행에서 일하세요?\n",
            "정답문장:  Do you work at a City bank? \n",
            "번역문장:  Could you let me know the March Mark? \n",
            "-----------------------------------\n",
            "입력문장:  이 제품을 사용할 때 예기치 않은 추락의 경우를 고려하면, 안전을 생각하여 잔디밭이 필요합니다.\n",
            "정답문장:  Also, this product needs a grass field for safety considering unexpected falls. \n",
            "번역문장:  I will send you the divers after the price after 20 years ago. \n",
            "-----------------------------------\n",
            "입력문장:  추가로 작성해서 내일까지 보내줄게요.\n",
            "정답문장:  I'll fill it out and send it to you by tomorrow. \n",
            "번역문장:  I will send you the best after company and the send of the stope. \n",
            "-----------------------------------\n",
            "입력문장:  \"유괴\"는 스코틀랜드를 배경으로 한 모험 소설이며 문학적 완성도 또한 높은 소설이에요.\n",
            "정답문장:  \"Kidnapped\" is an adventure story set in Scotland with high literary significance. \n",
            "번역문장:  And the send of the second floor selected and sent is below. \n",
            "-----------------------------------\n",
            "입력문장:  \"공식 초청 레터\"를 받는 데로 비자를 받을 것입니다.\n",
            "정답문장:  I will get my visa as soon as I receive the \" official invitation letter\". \n",
            "번역문장:  I was a preside to be a place to be a company on the 20th of A. \n",
            "-----------------------------------\n",
            "입력문장:  \"비타민 라인\"은 당신의 피부에 생기를 가득 채워주며 매끈한 피부결을 주는 산뜻함 그 자체입니다.\n",
            "정답문장:  \"Vitamin Line\" is freshness itself that fills your face with life and makes your skin feeling smooth. \n",
            "번역문장:  Marlows is the store to be a little bus changed on the 20th on April 2nd. \n",
            "-----------------------------------\n",
            "입력문장:  44C 수송 마지막 날짜를 12월 20일로 수정해주세요.\n",
            "정답문장:  Please amend 44C latest date of shipment to December 20th. \n",
            "번역문장:  Please check the amount of the 12 people and the second products. \n",
            "-----------------------------------\n",
            "입력문장:  Intergard 475 paint에 대해서는, 내일 작업을 시작할 예정입니다.\n",
            "정답문장:  For Intergard 475 paint , we'll start work tomorrow. \n",
            "번역문장:  Fot the same the sen of the second with a simple excelted. \n",
            "-----------------------------------\n",
            "입력문장:  간다 양이 암이라고 저는 들었어요.\n",
            "정답문장:  I heard that Miss Kanda has cancer. \n",
            "번역문장:  I have a reservation in the same of the store and the same of the May. \n",
            "-----------------------------------\n",
            "입력문장:  김치와 단무지 외에는 또 다른 반찬은 없어.\n",
            "정답문장:  There is no other side dishes except Kimchi and pickled radish. \n",
            "번역문장:  There are a lot of selected and sent of the same as below. \n",
            "-----------------------------------\n",
            "입력문장:  데이지 헤드는 추가 구매가 가능합니다.\n",
            "정답문장:  You can purchase additional Daisy head. \n",
            "번역문장:  Jacam was a place to the company on the getter. \n",
            "-----------------------------------\n",
            "입력문장:  오만과 편견이라는 책을 보면 다시가 무도회장에서 어떤 여성하고도 말을 섞지 않는 장면이 나옵니다.\n",
            "정답문장:  In the book called Pride and Prejudice, there is a scene when Darcy doesn't talk with any woman in the ballroom. \n",
            "번역문장:  The product of the sample of the product as soon as possible. \n",
            "1gram bleu Score:2.3810\n",
            "Stanrd bleu Score:0.0000\n"
          ]
        }
      ],
      "source": [
        "def translate_seq2seq(show_text=None):\n",
        "    bleu_score = []\n",
        "    for seq_index in [1, 20, 30, 40, 50, 60, 100, 200, 300, 400, 500, 1000]: # 입력 문장 인덱스\n",
        "        input_seq = encoder_input[seq_index:seq_index+1]\n",
        "        decoded_sentence = decode_sequence(input_seq)\n",
        "        score = sentence_bleu(\n",
        "            list(map(lambda ref: ref.split(), df.tar[seq_index][2:len(df.tar[seq_index])-1])),\n",
        "            df.tar[seq_index][2:len(df.tar[seq_index])-1].split(),\n",
        "            weights=(1, 0, 0, 0)\n",
        "        )\n",
        "        \n",
        "        bleu_score.append(score)\n",
        "        if show_text:\n",
        "            print(35 * '-')\n",
        "            print('입력문장: ', df.src[seq_index])\n",
        "            print('정답문장: ', df.tar[seq_index][2:len(df.tar[seq_index])-1]) # \\t 와 \\n 빼고 출력\n",
        "            print('번역문장: ', decoded_sentence[1:len(decoded_sentence)-1]) # \\n을 빼고 출력\n",
        "        \n",
        "    return print(\"1gram bleu Score:{0:0.4f}\".format(median(bleu_score) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j3n7nTsUZfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQHkByUTUZfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FByig1H4UZfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1q31yBXUZfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kSeEX9PUZfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ObewQeyUZfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdArAzbUUZfv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "20b65602904a6ff3fc15d4434a7c8a93588f98c76b1baa36944f5d2c44ba5b97"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}